{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is meant to tune the hyperparameters of the Linear and RNN models. 500 random combinations are trained for 100 epochs with early stopping using MSE as a loss function. The combination that produces the lowest validation loss is then chosen and those parameters saved to be used in the final model training. A brief experiment on the impact of stacking GRU layers on model performance is also included.<br>\n",
    "\n",
    "Last updated: 4/15/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from json import dump\n",
    "# PyTorch imports\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# Local import\n",
    "from tools import train_model, evaluate_model, best_hyperparameter_results, visualize_all_hyperparameter_results, EarlyStopping, get_dataloaders\n",
    "from models import SimpleNet, BaseballRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(\"Using:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip freeze > requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Create Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset and dataloaders are used for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved tensor for inputs and targest\n",
    "input_values = torch.load('./datasets/input_values.pth')\n",
    "target_values = torch.load('./datasets/target_values.pth')\n",
    "\n",
    "# Create Dataset\n",
    "dataset = TensorDataset(input_values, target_values)\n",
    "\n",
    "# Split and scale original dataset\n",
    "train_dataset, valid_dataset, test_dataset = get_dataloaders(dataset)\n",
    "\n",
    "# Create consistent test dataloader\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of random combinations to sample\n",
    "num_random_combinations = 500  \n",
    "\n",
    "# Define hyperparameters to test\n",
    "testing_params = {\n",
    "    'batch_size': [16, 32, 64, 128, 256],\n",
    "    'lr': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "    'mlp_dropout': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'weight_decay': [0.0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'hidden_size': [8, 16, 64, 128, 256],\n",
    "    'grad_clip': [None, 0.5, 1.0, 2.0, 5.0]\n",
    "}\n",
    "\n",
    "# Generate random combinations\n",
    "random_param_combinations = [\n",
    "    (\n",
    "        random.choice(testing_params['batch_size']),\n",
    "        random.choice(testing_params['lr']),\n",
    "        random.choice(testing_params['mlp_dropout']),\n",
    "        random.choice(testing_params['weight_decay']),\n",
    "        random.choice(testing_params['hidden_size']),\n",
    "        random.choice(testing_params['grad_clip'])\n",
    "    )\n",
    "    for _ in range(num_random_combinations)\n",
    "]\n",
    "\n",
    "# Save what parameters are being tested\n",
    "mlp_hyperparam_testing = pd.DataFrame(random_param_combinations, columns=testing_params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "num_epochs = 100\n",
    "early_stop_patience = 15\n",
    "loss = 'MSE'\n",
    "\n",
    "# Initialize tqdm progress bar to track progress through iterations\n",
    "pbar = tqdm(random_param_combinations, desc=\"Training Models\", total=len(random_param_combinations))\n",
    "\n",
    "# Iterate over parameter combinations\n",
    "for i, (batch_size, lr, mlp_dropout, weight_decay, hidden_size, grad_clip) in enumerate(pbar):\n",
    "\n",
    "    # Turn dataset into Dataloaders\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Create model\n",
    "    input_size, seq_len = valid_dataloader.dataset[0][0].shape\n",
    "    simple_baseball_mlp = SimpleNet(input_size=input_size, seq_len=seq_len, hidden_features=hidden_size, dropout=mlp_dropout).to(DEVICE)\n",
    "\n",
    "    # Optimizer and early stopper\n",
    "    optimizer = Adam(simple_baseball_mlp.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    early_stopper = EarlyStopping(patience=early_stop_patience, min_delta=0.0001)\n",
    "\n",
    "    # Training\n",
    "    eval_log = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Validation loss\n",
    "        avg_valid_loss = train_model(simple_baseball_mlp, optimizer, valid_dataloader, DEVICE, loss_fn=loss, grad_clip=grad_clip)\n",
    "        eval_log.append(avg_valid_loss)\n",
    "    \n",
    "        # Early Stopping\n",
    "        early_stopper(avg_valid_loss)\n",
    "        if early_stopper.early_stop:\n",
    "            #print(f\"Early stopping at epoch {epoch}\")\n",
    "            break    \n",
    "    \n",
    "    # Save results\n",
    "    results[i] = [eval_log]\n",
    "\n",
    "    # Final evaluation\n",
    "    valid_accuracy = evaluate_model(model=simple_baseball_mlp, dataloader=test_dataloader, device=DEVICE, loss_fn=loss)\n",
    "    # Save results\n",
    "    results[i].append(valid_accuracy)\n",
    "    results[i].append(f'Batch size: {batch_size}, lr: {lr}, dropout: {mlp_dropout}\\n l2: {weight_decay}, hidden_size: {hidden_size}, grad_clip: {grad_clip}\\n{loss}: {valid_accuracy:.4}')\n",
    "    # Append training epochs\n",
    "    results[i].append(epoch+1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the models, first by lowest RSME. Also visualize results to make sure that they aren't overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameter_results(results, loss=loss, n_best=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full results to csv\n",
    "mlp_hyperparam_testing['result_variance'] = [np.var(results[i][0]) for i in results]\n",
    "mlp_hyperparam_testing['tuning_epochs'] = [results[i][3] for i in results]\n",
    "mlp_hyperparam_testing[f'tuning_loss_{loss}'] = [results[i][1] for i in results]\n",
    "mlp_hyperparam_testing.to_csv('./tuning/mlp_hyperparameter_tuning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine best hyperparameters based on loss\n",
    "min_index = mlp_hyperparam_testing['tuning_loss_MSE'].idxmin()\n",
    "best_mlp_params = mlp_hyperparam_testing.iloc[min_index].to_dict()\n",
    "print(\"Best MLP Parameters:\")\n",
    "for key in best_mlp_params:\n",
    "    print(f\"{key}: {best_mlp_params[key]}\")\n",
    "\n",
    "# Write these results to file\n",
    "with open('./tuning/mlp_best_params.json', 'w') as file:\n",
    "    best_mlp_params.pop('tuning_loss_MSE', None)\n",
    "    best_mlp_params.pop('result_variance', None)\n",
    "    best_mlp_params.pop('tuning_epochs', None)\n",
    "\n",
    "    dump(best_mlp_params, file, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Network\n",
    "\n",
    "A many-to-one RNN using gated recurrence units (GRUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of random combinations to sample\n",
    "num_random_combinations = 500  \n",
    "\n",
    "# Define hyperparameters to test\n",
    "testing_params = {\n",
    "    'batch_size': [16, 32, 64, 128, 256],\n",
    "    'n_layers': [1, 2, 3, 5],\n",
    "    'lr': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "    'rnn_dropout': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'weight_decay': [0.0, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'grad_clip': [None, 0.5, 1.0, 2.0, 5.0],\n",
    "    'hidden_size': [8, 16, 64, 128, 256],\n",
    "}\n",
    "\n",
    "# Generate random combinations\n",
    "random_param_combinations = [\n",
    "    (\n",
    "        random.choice(testing_params['batch_size']),\n",
    "        random.choice(testing_params['n_layers']),\n",
    "        random.choice(testing_params['lr']),\n",
    "        random.choice(testing_params['rnn_dropout']),\n",
    "        random.choice(testing_params['weight_decay']),\n",
    "        random.choice(testing_params['grad_clip']),\n",
    "        random.choice(testing_params['hidden_size'])\n",
    "    )\n",
    "    for _ in range(num_random_combinations)\n",
    "]\n",
    "\n",
    "# Save what parameters are being tested\n",
    "rnn_hyperparam_testing = pd.DataFrame(random_param_combinations, columns=testing_params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rnn = {}\n",
    "num_epochs = 100\n",
    "early_stop_patience = 15\n",
    "loss = 'MSE'\n",
    "\n",
    "# Initialize tqdm progress bar to track progress through 144 iterations\n",
    "pbar = tqdm(random_param_combinations, desc=\"Training Models\", total=len(random_param_combinations))\n",
    "\n",
    "# Iterate over parameter combinations\n",
    "for i, (batch_size, n_layers, lr, rnn_dropout, weight_decay, grad_clip, hidden_size) in enumerate(pbar):\n",
    "\n",
    "    # Turn into Dataloaders\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    # Create model\n",
    "    input_size = valid_dataloader.dataset[0][0].size()[1]\n",
    "    baseball_rnn = BaseballRNN(input_size=input_size, hidden_size=hidden_size, n_layers=n_layers,\n",
    "                                hidden_init='rand', rnn_dropout=rnn_dropout).to(DEVICE)\n",
    "\n",
    "    # Optimizer and early stopping\n",
    "    optimizer = Adam(baseball_rnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    early_stopper = EarlyStopping(patience=early_stop_patience, min_delta=0.0001)\n",
    "\n",
    "    # Training\n",
    "    eval_log_rnn = []\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Validation loss\n",
    "        avg_valid_loss = train_model(baseball_rnn, optimizer, valid_dataloader, DEVICE, loss_fn=loss, grad_clip=grad_clip)\n",
    "        eval_log_rnn.append(avg_valid_loss)\n",
    "        # Early Stopping\n",
    "        early_stopper(avg_valid_loss)\n",
    "        if early_stopper.early_stop:\n",
    "            #print(f\"Early stopping at epoch {epoch}\")\n",
    "            break    \n",
    "\n",
    "    # Save results\n",
    "    results_rnn[i] = [eval_log_rnn] \n",
    "\n",
    "    # Test evaluation\n",
    "    test_accuracy_rnn = evaluate_model(model=baseball_rnn, dataloader=test_dataloader, device=DEVICE, loss_fn=loss)\n",
    "    # Save results\n",
    "    results_rnn[i].append(test_accuracy_rnn)\n",
    "    results_rnn[i].append(f'Batch size:{batch_size}, lr:{lr}, n_layers:{n_layers}, dropout:{mlp_dropout}\\n l2:{weight_decay}, hidden_size:{hidden_size}, grad_clip:{grad_clip}\\n{loss}: {test_accuracy_rnn:.4}')\n",
    "\n",
    "    # Append training epochs\n",
    "    results_rnn[i].append(epoch+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameter_results(results_rnn, loss=loss, n_best=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full results to csv\n",
    "mlp_hyperparam_testing['result_variance'] = [np.var(results_rnn[i][0]) for i in results_rnn]\n",
    "rnn_hyperparam_testing['tuning_epochs'] = [results_rnn[i][3] for i in results_rnn]\n",
    "rnn_hyperparam_testing[f'tuning_loss_{loss}'] = [results_rnn[i][1] for i in results_rnn]\n",
    "rnn_hyperparam_testing.to_csv('./tuning/rnn_hyperparameter_tuning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine best hyperparameters based on loss\n",
    "min_index = rnn_hyperparam_testing['tuning_loss_MSE'].idxmin()\n",
    "best_rnn_params = rnn_hyperparam_testing.iloc[min_index].to_dict()\n",
    "print(\"Best RNN Parameters:\")\n",
    "for key in best_rnn_params:\n",
    "    print(f\"{key}: {best_rnn_params[key]}\")\n",
    "\n",
    "# Write these results to file\n",
    "with open('./tuning/rnn_best_params.json', 'w') as file:\n",
    "    best_rnn_params.pop('tuning_loss_MSE', None)\n",
    "    best_rnn_params.pop('result_variance', None)\n",
    "    best_rnn_params.pop('tuning_epochs', None)\n",
    "\n",
    "    dump(best_rnn_params, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Layer Experiment\n",
    "\n",
    "Showing effect of the number of RNN layers on final model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and move it to the appropriate device\n",
    "layers = [1, 2, 5, 10, 20, 50]\n",
    "layer_losses = {layer: [] for layer in layers}\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "# Get best hyperparameters from tuning\n",
    "lr = best_rnn_params['lr']\n",
    "grad_clip = best_rnn_params['grad_clip']\n",
    "#batch_size = best_rnn_params_layer['batch_size']\n",
    "weight_decay = best_rnn_params['weight_decay']\n",
    "hidden_size = int(best_rnn_params['hidden_size'])\n",
    "rnn_dropout = best_rnn_params['rnn_dropout']\n",
    "\n",
    "# Run experiment\n",
    "for rnn_layer in layers:\n",
    "\n",
    "    # Initialize model\n",
    "    input_size = test_dataloader.dataset[0][0].size()[1]\n",
    "    RNN_model = BaseballRNN(input_size=input_size, rnn_dropout=rnn_dropout, hidden_size=hidden_size, n_layers=rnn_layer).to(DEVICE)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    optimizer = torch.optim.Adam(RNN_model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Training loop\n",
    "    pbar = tqdm(range(num_epochs), desc=f\"Training RNN ({rnn_layer} layers)\")\n",
    "    for epoch in pbar:\n",
    "\n",
    "        # Get average loss over batches for training\n",
    "        avg_train_loss = train_model(RNN_model, optimizer, test_dataloader, DEVICE, loss_fn='RMSE', grad_clip=grad_clip)\n",
    "        avg_valid_loss = evaluate_model(RNN_model, valid_dataloader, DEVICE, loss_fn='RMSE')\n",
    "\n",
    "        layer_losses[rnn_layer].append(avg_train_loss)\n",
    "        #dropout_losses[rnn_dropout][1].append(avg_train_loss)\n",
    "\n",
    "        pbar.set_postfix({'Train loss': avg_train_loss, 'Validation loss': avg_valid_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss over time\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(f'Effect of Layers on Model Performance and Generalization', fontsize=12)\n",
    "#plt.title(f'(Solid: Training Loss. Dashed: Validation Loss)', fontsize=10)\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.xlabel('Epoch')\n",
    "colors = ['r', 'g', 'b', 'y', 'c', 'black']\n",
    "colors = ['#006BA4', '#FF800E', '#ABABAB', '#595959', '#A2C8EC', \"#000000\"]\n",
    "for i, layer in enumerate(layer_losses):\n",
    "    #plt.plot(dropout_losses[dp][0], label=dp, linestyle='solid')\n",
    "    plt.plot(layer_losses[layer], linestyle='solid', c=colors[i], label=layer)\n",
    "#plt.plot(np.array([layer_losses[dl][1] for dl in layer_losses]).mean(axis=0), color='black')\n",
    "plt.legend(title='RNN Layers', loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
